{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !git clone https://github.com/nikitakapitan/nlphub.git\n",
    "# !mkdir logs\n",
    "# !pip install datasets transformers evaluate accelerate\n",
    "\n",
    "# %cd nlphub\n",
    "# !pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "from nlphub import ClassificationBenchmark\n",
    "\n",
    "TASK = \"text-classification\"\n",
    "BenchmarkClass = ClassificationBenchmark\n",
    "DATASET_NAME = \"imdb\"\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "\n",
    "GLUE_TASKS = [\"cola\", \"mnli\", \"mrpc\", \"qnli\", \"qqp\", \"rte\", \"sst2\", \"stsb\", \"wnli\"]\n",
    "METRICS = [ {'accuracy'   : {}},\n",
    "            {'f1'         : {'average': 'weighted'}},\n",
    "            {'glue'       : GLUE_TASKS}] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(DATASET_NAME, split='test')\n",
    "\n",
    "# truncation : crop input text to model max_length | device=0 : first available GPU\n",
    "pipe = pipeline(TASK, model=MODEL_NAME, truncation=True, device=0) \n",
    "benchmark = BenchmarkClass(pipe, dataset, METRICS)\n",
    "metrics = benchmark.run_benchmark()\n",
    "\n",
    "with open('results.json', 'w') as f:\n",
    "    setup = f\"Compute {METRICS} for task={TASK} on dataset={DATASET_NAME} using model={MODEL_NAME}\"\n",
    "    json.dump({'setup':setup, 'metrics' : metrics}, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
