{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this colab we:\n",
    "1. Import CNN dailymail (news, summarization) pairs.\n",
    "2. SUMMARIZE first example (about Hary Potter)\n",
    "    - baseline = first 3 senteces of article\n",
    "    - GPT-2 = append TL;DR and generate next tokens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers datasets rouge_score sacrebleu evaluate py7zr pynvml xformers sentencepiece accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nikit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Found cached dataset cnn_dailymail (C:/Users/nikit/.cache/huggingface/datasets/cnn_dailymail/default/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666a7711886b4f5c971ef37f301e26cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import transformers\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "cnn_dataset = load_dataset(\"cnn_dailymail\", version=\"3.0.0\")\n",
    "cnn_dataset['train'].column_names\n",
    "\n",
    "summaries = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him. Daniel ...\n",
      "- - - - -\n",
      "Harry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday .\n",
      "Young actor says he has no plans to fritter his cash away .\n",
      "Radcliffe's earnings from first five Potter films have been held in trust fund .\n"
     ]
    }
   ],
   "source": [
    "sample = cnn_dataset['train'][0]\n",
    "print(sample['article'][29:211], '...')\n",
    "print('- - - - -')\n",
    "print(sample['highlights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROUND TRUTH\n",
      "Harry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday .\n",
      "Young actor says he has no plans to fritter his cash away .\n",
      "Radcliffe's earnings from first five Potter films have been held in trust fund . \n",
      "\n",
      "BASELINE\n",
      "LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\"To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \n",
      "\n",
      "GPT2\n",
      "Rudyard Kipling's youngest son is coming of age in \"Harry Potter and the Order of the Phoenix.\"Expect Radcliffe's first Potter film to break box office records in the UK, in spite of poor box office and ratings.If Radcliffe can't hit box office records, can the franchise live on in a different form?Thanks,  @SophieSchlutterer @TessBell @Gwen Blockchain.org  @jimmymonnett. \n",
      "\n",
      "T5\n",
      "the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties .he will be able to gamble in a casino, buy a drink or see the horror film \"Hostel: Part II\" his agent and publicist had no comment on his plans .his latest outing as the boy wizard is breaking records on both sides of the Atlantic . \n",
      "\n",
      "BART\n",
      "Harry Potter star Daniel Radcliffe turns 18 on Monday.He gains access to a reported £20 million ($41.1 million) fortune.Radcliffe's earnings from the first five Potter films have been held in a trust fund.Details of how he'll mark his landmark birthday are under wraps. \n",
      "\n",
      "PEGASUS\n",
      "Harry Potter star Daniel Radcliffe gains access to a reported £20 million fortune.\n",
      "Young actor says he has no plans to fritter his cash away.\n",
      "Radcliffe's earnings from the first five Potter films have been held in a trust fund . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Baseline = first 3 senteces\n",
    "def three_sentence_summary(text):\n",
    "    return \" \".join(nltk.sent_tokenize(text)[:3])\n",
    "summaries['baseline'] = three_sentence_summary(sample['article'][:1000])\n",
    "\n",
    "# GPT-2 (not trained to SUMMARIZE but at least we can give a shot by appending \"TL;DR\")\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    gpt2_query = sample['article']  + \"\\nTL;DR:\\n\"\n",
    "    gpt2_pipe = transformers.pipeline(\"text-generation\", model=\"gpt2-xl\")\n",
    "    gpt2_out = gpt2_pipe(gpt2_query, max_length=1024, clean_up_tokenization_spaces=True)\n",
    "    summaries['gpt2'] = \"\".join(nltk.sent_tokenize(gpt2_out[0][\"generated_text\"][len(gpt2_query) :]))\n",
    "\n",
    "    # T5 fine-tuned on Summarization (CNN/DailyMail included)\n",
    "    t5_pipe = transformers.pipeline(\"summarization\", model=\"t5-large\")\n",
    "    t5_out = t5_pipe(sample['article'])\n",
    "    summaries['t5'] = \"\".join(nltk.sent_tokenize(t5_out[0][\"summary_text\"]))\n",
    "\n",
    "    # BART exclusively fine-tuned on CNN/DailyMail\n",
    "    bart_pipe = transformers.pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "    bart_out = bart_pipe(sample['article'])\n",
    "    summaries['bart'] = \"\".join(nltk.sent_tokenize(bart_out[0][\"summary_text\"]))\n",
    "\n",
    "    \n",
    "    # PEGASUS exclusively fine-tuned on CNN/DailyMail\n",
    "    pegasus_pipe = transformers.pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\")\n",
    "    pegasus_out = pegasus_pipe(sample['article'])\n",
    "    summaries['pegasus'] = \"\".join(nltk.sent_tokenize(pegasus_out[0][\"summary_text\"])).replace(\" .<n>\", \".\\n\") \n",
    "    \n",
    "else: # import results\n",
    "    with open('files/harry0_summaries_gpt2_t5_bart_pegasus.json', 'r') as file:\n",
    "        summaries = json.load(file)\n",
    " \n",
    "\n",
    "print(\"GROUND TRUTH\")\n",
    "print(sample['highlights'], '\\n')    \n",
    "\n",
    "for model_name in summaries:\n",
    "    print(model_name.upper())\n",
    "    print(summaries[model_name], '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's compute BLEU and also ROUGE\n",
    "\n",
    "First on Harry Potter sample, then on the whole CNN/DailyMail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge & Bleu for SINGLE \"Harry Potter\" example by MODEL:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>sacre_bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.335484</td>\n",
       "      <td>0.248366</td>\n",
       "      <td>0.296774</td>\n",
       "      <td>0.335484</td>\n",
       "      <td>13.078777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>0.174757</td>\n",
       "      <td>0.039604</td>\n",
       "      <td>0.135922</td>\n",
       "      <td>0.174757</td>\n",
       "      <td>1.473461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t5</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.213592</td>\n",
       "      <td>0.247619</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>14.509719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bart</th>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>28.544473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pegasus</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>64.657462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rouge1    rouge2    rougeL  rougeLsum  sacre_bleu\n",
       "baseline  0.335484  0.248366  0.296774   0.335484   13.078777\n",
       "gpt2      0.174757  0.039604  0.135922   0.174757    1.473461\n",
       "t5        0.285714  0.213592  0.247619   0.266667   14.509719\n",
       "bart      0.613636  0.372093  0.545455   0.568182   28.544473\n",
       "pegasus   0.800000  0.692308  0.800000   0.800000   64.657462"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Bleu & Rouge on \"Harry Potter\"\n",
    "\n",
    "bleu_metric = evaluate.load(\"sacrebleu\")\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "records = []\n",
    "\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "\n",
    "for model_name in summaries:\n",
    "    predictions = [summaries[model_name]]\n",
    "    references = [sample['highlights']]\n",
    "\n",
    "    rouge_score = rouge_metric.compute(predictions=predictions, references=references)\n",
    "    bleu_score = bleu_metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "    record_dict = {**rouge_score, 'sacre_bleu' : bleu_score['score']}\n",
    "\n",
    "    records.append(record_dict)\n",
    "\n",
    "print('Rouge & Bleu for SINGLE \"Harry Potter\" example by MODEL:')\n",
    "pd.DataFrame.from_records(records, index=summaries.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at C:\\Users\\nikit\\.cache\\huggingface\\datasets\\cnn_dailymail\\default\\3.0.0\\1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de\\cache-888acb9a2eb72e89.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Rouge & Bleu for 1k-CNN DATASET for MODEL=BASELINE:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.396061</td>\n",
       "      <td>0.173995</td>\n",
       "      <td>0.245815</td>\n",
       "      <td>0.361158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rouge1    rouge2    rougeL  rougeLsum\n",
       "baseline  0.396061  0.173995  0.245815   0.361158"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate BASELINE Rouge on 1k CNN/DailyMail\n",
    "cnn_test_sampled = cnn_dataset['test'].shuffle(seed=42).select(range(1000))\n",
    "\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "bleu_metric = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "def evaluate_summaries_baseline(dataset, metric,\n",
    "                                column_text=\"article\",\n",
    "                                column_summary=\"highlights\"):\n",
    "    summaries = [three_sentence_summary(text) for text in dataset[column_text]]\n",
    "    metric.add_batch(predictions=[summaries],\n",
    "                     references=[dataset[column_summary]])\n",
    "    score = metric.compute()\n",
    "    return score\n",
    "\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    rouge_score = evaluate_summaries_baseline(cnn_test_sampled, rouge_metric)\n",
    "    bleu_score = evaluate_summaries_baseline(cnn_test_sampled, bleu_metric)\n",
    "\n",
    "    metrics = rouge_score\n",
    "    metrics['sacre_bleu'] = bleu_score['score']\n",
    "else:\n",
    "    with open('files/baseline@cnn.json', 'r') as file:\n",
    "        metrics = json.load(file)\n",
    "\n",
    "print('\\033[1m' + '\\nRouge & Bleu for 1k-CNN DATASET for MODEL=BASELINE:' + '\\033[0m')\n",
    "pd.DataFrame.from_dict(metrics, orient=\"index\", columns=[\"baseline\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Rouge & Bleu for 1k-CNN DATASET for MODEL=PEGASUS FT@CNN:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pegasus</th>\n",
       "      <td>0.434365</td>\n",
       "      <td>0.216317</td>\n",
       "      <td>0.312109</td>\n",
       "      <td>0.37413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           rouge1    rouge2    rougeL  rougeLsum\n",
       "pegasus  0.434365  0.216317  0.312109    0.37413"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate PEGASUS Rouge on CNN/DailyMail\n",
    "import os, json, pandas\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "\n",
    "\n",
    "def chunks(list_of_elements, batch_size):\n",
    "    \"\"\"Yield successive batch-sized chunks from list_of_elements.\"\"\"\n",
    "    for i in range(0, len(list_of_elements), batch_size):\n",
    "        yield list_of_elements[i : i + batch_size]\n",
    "\n",
    "def evaluate_summaries_pegasus(dataset, metric, model, tokenizer,\n",
    "                               batch_size=16, device='cuda',\n",
    "                               column_text=\"article\",\n",
    "                               column_summary=\"highlights\"):\n",
    "    article_batches = list(chunks(dataset[column_text], batch_size))\n",
    "    target_batches = list(chunks(dataset[column_summary], batch_size))\n",
    "\n",
    "    for article_batch, target_batch in tqdm(\n",
    "        zip(article_batches, target_batches), total=len(article_batches)):\n",
    "\n",
    "        inputs = tokenizer(article_batch, max_length=1024,  truncation=True,\n",
    "                        padding=\"max_length\", return_tensors=\"pt\")\n",
    "\n",
    "        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
    "                         attention_mask=inputs[\"attention_mask\"].to(device),\n",
    "                         length_penalty=0.8, num_beams=8, max_length=128)\n",
    "\n",
    "        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n",
    "                                clean_up_tokenization_spaces=True)\n",
    "               for s in summaries]\n",
    "        decoded_summaries = [d.replace(\"<n>\", \" \") for d in decoded_summaries]\n",
    "        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
    "\n",
    "    score = metric.compute()\n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    cnn_test_sampled = cnn_dataset['test'].shuffle(seed=42).select(range(1000))\n",
    "    rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "    model_ckpt = \"google/pegasus-cnn_dailymail\"\n",
    "    pegasus_tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "    pegasus_model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\n",
    "    score = evaluate_summaries_pegasus(cnn_test_sampled, rouge_metric, pegasus_model, pegasus_tokenizer, batch_size=8)\n",
    "else:\n",
    "    with open('files/cnn_pegasus@cnn.json', 'r') as file:\n",
    "        score = json.load(file)\n",
    "\n",
    "# published paper results: \n",
    "# R1 - 0.439, R2 - 0.212, RL - 0.407\n",
    "\n",
    "print('\\033[1m' + '\\nRouge & Bleu for 1k-CNN DATASET for MODEL=PEGASUS FT@CNN:' + '\\033[0m')\n",
    "pandas.DataFrame(score, index=['pegasus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune Pegasus on SAMSum\n",
    "Consider Summarization for another dataset : Dialogues (SAMSum).\n",
    "- The summarization should be more abstract and written from third-person-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Found cached dataset samsum (C:/Users/nikit/.cache/huggingface/datasets/samsum/samsum/0.0.0/f1d7c6b7353e6de335d444e424dc002ef70d1277109031327bc9cc6af5d3d46e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aaef522ab434e79aed650b1b10241d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: train:14,732 - teset:819 - validation:818\n",
      "Dialogue:\n",
      "Hannah: Hey, do you have Betty's number?\n",
      "Amanda: Lemme check\n",
      "Hannah: <file_gif>\n",
      "Amanda: Sorry, can't find it.\n",
      "Amanda: Ask Larry\n",
      "Amanda: He called her last time we were at the park together\n",
      "Hannah: I don't know him well\n",
      "Hannah: <file_gif>\n",
      "Amanda: Don't be shy, he's very nice\n",
      "Hannah: If you say so..\n",
      "Hannah: I'd rather you texted him\n",
      "Amanda: Just text him 🙂\n",
      "Hannah: Urgh.. Alright\n",
      "Hannah: Bye\n",
      "Amanda: Bye bye\n",
      "\n",
      "Summary:\n",
      "Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_ckpt = \"google/pegasus-cnn_dailymail\"\n",
    "pegasus_tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "pegasus_model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\n",
    "\n",
    "dataset_samsum = load_dataset('samsum')\n",
    "print('Dataset size: train:14,732 - teset:819 - validation:818')\n",
    "\n",
    "samsum_sample = dataset_samsum['test'][0]\n",
    "print('Dialogue:')\n",
    "print(samsum_sample['dialogue'])\n",
    "print('\\nSummary:')\n",
    "print(samsum_sample['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's zero-shot PEGASUS on Hannah example\n",
    "pegasus_pipe = transformers.pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\")\n",
    "pegasus_out = pegasus_pipe(dataset_samsum['test'][0]['dialogue'])\n",
    "print('Pegasus summary:')\n",
    "print(pegasus_out[0]['summary_text'].replace(' .<n>', '.\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the model tries to summarize by extracting the key sentences. \n",
    "- That is OK for CNN/DailyMail but not SAMSum\n",
    "\n",
    "Let's compute zero-shot **Rouge** of PEGASUS on whole SAMSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Rouge on DATASET=819.SAMSum for MODEL=PEGASUS:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pegasus</th>\n",
       "      <td>0.296198</td>\n",
       "      <td>0.087426</td>\n",
       "      <td>0.22933</td>\n",
       "      <td>0.229199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           rouge1    rouge2   rougeL  rougeLsum\n",
       "pegasus  0.296198  0.087426  0.22933   0.229199"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's zero-shot PEGASUS on Hannah example (819 examples | 27 GB VRAM required | ~10 min A100 GPU)\n",
    "\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    model_ckpt = \"google/pegasus-cnn_dailymail\"\n",
    "    pegasus_tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "    pegasus_model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\n",
    "\n",
    "    rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "    score = evaluate_summaries_pegasus(dataset=dataset_samsum['test'].select(range(300)), \n",
    "                                        metric=rouge_metric,\n",
    "                                        model=pegasus_model,\n",
    "                                        tokenizer=pegasus_tokenizer,\n",
    "                                        column_text='dialogue',\n",
    "                                        column_summary='summary',\n",
    "                                        batch_size=8)\n",
    "else:\n",
    "    with open('files/cnn_pegasus@samsum.json', 'r') as file:\n",
    "        score = json.load(file)\n",
    "\n",
    "\n",
    "# HG book: R1 - 0.296, R2 - 0.088, RL - 0.230, RLsum - 0.230\n",
    "print('\\033[1m' + '\\nRouge on DATASET=819.SAMSum for MODEL=PEGASUS:' + '\\033[0m')\n",
    "pd.DataFrame(score, index=[\"pegasus\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e89a616dc6ca439ea1ad177c6c73b438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14732 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nikit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b57d094e6494402ab935f40cdb842c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/819 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08ef455040f249838bf579910e70748e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/818 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare data for fine-tuning\n",
    "\n",
    "def cast_dataset_to_features(batch):\n",
    "\n",
    "    input_encodings = pegasus_tokenizer(batch['dialogue'], max_length=1024, truncation=True)\n",
    "    with pegasus_tokenizer.as_target_tokenizer():\n",
    "        target_encodings = pegasus_tokenizer(batch['summary'], max_length=128, truncation=True)\n",
    "    \n",
    "    return {'input_ids' : input_encodings['input_ids'],\n",
    "            'attention_mask' : input_encodings['attention_mask'],\n",
    "            'labels' : target_encodings['input_ids']}\n",
    "\n",
    "dataset_samsum_pt = dataset_samsum.map(cast_dataset_to_features, batched=True)\n",
    "\n",
    "columns = ['input_ids', 'labels', 'attention_mask']\n",
    "dataset_samsum_pt.set_format(type='torch', columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataccolator:\n",
    "- stack all tensors from batch\n",
    "- prepare decoder targets (teacher forcing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pegasus(FT:Samsum) evaluated on SamSum['test']:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.4267732831551504,\n",
       " 'rouge2': 0.19817278181827536,\n",
       " 'rougeL': 0.3425978145713223,\n",
       " 'rougeLsum': 0.3426185352735921}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    notebook_login() #             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\n",
    "\n",
    "    seq2seq_data_collator = DataCollatorForSeq2Seq(pegasus_tokenizer, model=pegasus_model)\n",
    "\n",
    "    training_args = TrainingArguments(output_dir='pegasus-samsum', num_train_epochs=1,\n",
    "    warmup_steps=500, per_device_train_batch_size=1, per_device_eval_batch_size=1,\n",
    "    weight_decay=0.01, logging_steps=10, push_to_hub=True, evaluation_strategy='steps',\n",
    "    eval_steps=500, save_steps=1e6, gradient_accumulation_steps=16)\n",
    "\n",
    "    trainer = Trainer(model=pegasus_model, args=training_args,\n",
    "                    tokenizer=pegasus_tokenizer, data_collator=seq2seq_data_collator,\n",
    "                    train_dataset=dataset_samsum_pt[\"train\"],\n",
    "                    eval_dataset=dataset_samsum_pt[\"validation\"])\n",
    "    \n",
    "    trainer.train() # T4 GPU 15GB ~ 50 min\n",
    "\n",
    "    score = evaluate_summaries_pegasus(dataset_samsum['test'], rouge_metric, trainer.model, pegasus_tokenizer,\n",
    "    batch_size=2, column_text='dialogue', column_summary='summary')\n",
    "\n",
    "    score = pd.DataFrame(score, index=['pegasus'])\n",
    "else:\n",
    "    with open('files/samsum_pegasus@samsum.json', 'r') as file:\n",
    "        score = json.load(file)\n",
    "print(\"Pegasus(FT:Samsum) evaluated on SamSum['test']:\")        \n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's generate Dialogue summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 128, but your input_length is only 122. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Amanda can't find Betty's number. Larry called Betty last time they were at the park together. Hannah wants Amanda to text Larry. Amanda will text Larry.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate Hannah dialogue summary:\n",
    "from transformers import pipeline\n",
    "\n",
    "gen_kwargs = {\"length_penalty\": 0.8, \"num_beams\":8, \"max_length\": 128}\n",
    "sample_text = dataset_samsum[\"test\"][0][\"dialogue\"]\n",
    "pipe = pipeline(\"summarization\", model=\"nikitakapitan/pegasus-samsum\")\n",
    "\n",
    "pipe(sample_text, **gen_kwargs)[0][\"summary_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 128, but your input_length is only 91. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=45)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Thom, Lewis and Leandro are going to write a book about transformers. Thom helped build a library by Hugging Face. Lewis and Leandro are going to do it together.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_dialogue = \"\"\"\\\n",
    "Thom: Hi guys, have you heard of transformers?\n",
    "Lewis: Yes, I used them recently!\n",
    "Leandro: Indeed, there is a great library by Hugging Face.\n",
    "Thom: I know, I helped build it ;)\n",
    "Lewis: Cool, maybe we should write a book about it. What do you think?\n",
    "Leandro: Great idea, how hard can it be?!\n",
    "Thom: I am in!\n",
    "Lewis: Awesome, let's do it together!\n",
    "\"\"\"\n",
    "\n",
    "pipe(custom_dialogue, **gen_kwargs)[0][\"summary_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
